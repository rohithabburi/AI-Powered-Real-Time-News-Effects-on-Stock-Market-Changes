{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf7eef-62ce-4929-bec0-674a7fb845c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3216\\3163433396.py:14: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MMM...\n",
      "Fetching data for AOS...\n",
      "Fetching data for ABT...\n",
      "Fetching data for ABBV...\n",
      "Fetching data for ACN...\n",
      "Fetching data for ADBE...\n",
      "Fetching data for AMD...\n",
      "Fetching data for AES...\n",
      "Fetching data for AFL...\n",
      "Fetching data for A...\n",
      "Fetching data for APD...\n",
      "Fetching data for ABNB...\n",
      "Fetching data for AKAM...\n",
      "Fetching data for ALB...\n",
      "Fetching data for ARE...\n",
      "Fetching data for ALGN...\n",
      "Fetching data for ALLE...\n",
      "Fetching data for LNT...\n",
      "Fetching data for ALL...\n",
      "Fetching data for GOOGL...\n",
      "Fetching data for GOOG...\n",
      "Fetching data for MO...\n",
      "Fetching data for AMZN...\n",
      "Fetching data for AMCR...\n",
      "Fetching data for AEE...\n",
      "Fetching data for AEP...\n",
      "Fetching data for AXP...\n",
      "Fetching data for AIG...\n",
      "Fetching data for AMT...\n",
      "Fetching data for AWK...\n",
      "Fetching data for AMP...\n",
      "Fetching data for AME...\n",
      "Fetching data for AMGN...\n",
      "Fetching data for APH...\n",
      "Fetching data for ADI...\n",
      "Fetching data for ANSS...\n",
      "Fetching data for AON...\n",
      "Fetching data for APA...\n",
      "Fetching data for APO...\n",
      "Fetching data for AAPL...\n",
      "Fetching data for AMAT...\n",
      "Fetching data for APTV...\n",
      "Fetching data for ACGL...\n",
      "Fetching data for ADM...\n",
      "Fetching data for ANET...\n",
      "Fetching data for AJG...\n",
      "Fetching data for AIZ...\n",
      "Fetching data for T...\n",
      "Fetching data for ATO...\n",
      "Fetching data for ADSK...\n",
      "Fetching data for ADP...\n",
      "Fetching data for AZO...\n",
      "Fetching data for AVB...\n",
      "Fetching data for AVY...\n",
      "Fetching data for AXON...\n",
      "Fetching data for BKR...\n",
      "Fetching data for BALL...\n",
      "Fetching data for BAC...\n",
      "Fetching data for BAX...\n",
      "Fetching data for BDX...\n",
      "Fetching data for BRK.B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRK.B: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for BRK.B\n",
      "Fetching data for BBY...\n",
      "Fetching data for TECH...\n",
      "Fetching data for BIIB...\n",
      "Fetching data for BLK...\n",
      "Fetching data for BX...\n",
      "Fetching data for BK...\n",
      "Fetching data for BA...\n",
      "Fetching data for BKNG...\n",
      "Fetching data for BWA...\n",
      "Fetching data for BSX...\n",
      "Fetching data for BMY...\n",
      "Fetching data for AVGO...\n",
      "Fetching data for BR...\n",
      "Fetching data for BRO...\n",
      "Fetching data for BF.B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BF.B: possibly delisted; no price data found  (1d 2024-12-25 -> 2025-02-09)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for BF.B\n",
      "Fetching data for BLDR...\n",
      "Fetching data for BG...\n",
      "Fetching data for BXP...\n",
      "Fetching data for CHRW...\n",
      "Fetching data for CDNS...\n",
      "Fetching data for CZR...\n",
      "Fetching data for CPT...\n",
      "Fetching data for CPB...\n",
      "Fetching data for COF...\n",
      "Fetching data for CAH...\n",
      "Fetching data for KMX...\n",
      "Fetching data for CCL...\n",
      "Fetching data for CARR...\n",
      "Fetching data for CAT...\n",
      "Fetching data for CBOE...\n",
      "Fetching data for CBRE...\n",
      "Fetching data for CDW...\n",
      "Fetching data for CE...\n",
      "Fetching data for COR...\n",
      "Fetching data for CNC...\n",
      "Fetching data for CNP...\n",
      "Fetching data for CF...\n",
      "Fetching data for CRL...\n",
      "Fetching data for SCHW...\n",
      "Fetching data for CHTR...\n",
      "Fetching data for CVX...\n",
      "Fetching data for CMG...\n",
      "Fetching data for CB...\n",
      "Fetching data for CHD...\n",
      "Fetching data for CI...\n",
      "Fetching data for CINF...\n",
      "Fetching data for CTAS...\n",
      "Fetching data for CSCO...\n",
      "Fetching data for C...\n",
      "Fetching data for CFG...\n",
      "Fetching data for CLX...\n",
      "Fetching data for CME...\n",
      "Fetching data for CMS...\n",
      "Fetching data for KO...\n",
      "Fetching data for CTSH...\n",
      "Fetching data for CL...\n",
      "Fetching data for CMCSA...\n",
      "Fetching data for CAG...\n",
      "Fetching data for COP...\n",
      "Fetching data for ED...\n",
      "Fetching data for STZ...\n",
      "Fetching data for CEG...\n",
      "Fetching data for COO...\n",
      "Fetching data for CPRT...\n",
      "Fetching data for GLW...\n",
      "Fetching data for CPAY...\n",
      "Fetching data for CTVA...\n",
      "Fetching data for CSGP...\n",
      "Fetching data for COST...\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to fetch S&P 500 tickers\n",
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Scrapes the S&P 500 tickers from Wikipedia.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        tables = pd.read_html(response.text)\n",
    "        sp500_tickers = tables[0]['Symbol'].tolist()\n",
    "        return sp500_tickers\n",
    "    else:\n",
    "        print(\"Failed to retrieve S&P 500 tickers.\")\n",
    "        return []\n",
    "\n",
    "# Get all S&P 500 tickers\n",
    "tickers = get_sp500_tickers()\n",
    "\n",
    "# Limit to 2000 tickers (If necessary, expand to other indices or random selections)\n",
    "if len(tickers) > 2000:\n",
    "    tickers = tickers[:2000]\n",
    "\n",
    "# Set the correct time range\n",
    "start_date = \"2024-12-25\"\n",
    "end_date = \"2025-02-09\"\n",
    "interval = \"1d\"  # Daily data\n",
    "\n",
    "# Function to fetch stock data\n",
    "def get_all_stock_data(tickers, start_date, end_date, interval):\n",
    "    \"\"\"\n",
    "    Fetches stock data for multiple companies and combines them into a single DataFrame.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching data for {ticker}...\")\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            data = stock.history(start=start_date, end=end_date, interval=interval)\n",
    "            \n",
    "            if not data.empty:\n",
    "                data[\"Ticker\"] = ticker  # Add a column to identify the stock\n",
    "                all_data.append(data)\n",
    "            else:\n",
    "                print(f\"No data found for {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    # Combine all data into one DataFrame\n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, axis=0)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Fetch stock data\n",
    "df = get_all_stock_data(tickers, start_date, end_date, interval)\n",
    "\n",
    "# Save to CSV if data is available\n",
    "if df is not None:\n",
    "    filename = \"sp500_stocks_custom_range67.csv\"\n",
    "    df.to_csv(filename)\n",
    "    print(f\"All stock data saved as {filename}\")\n",
    "    print(df.head())  # Display first few rows\n",
    "else:\n",
    "    print(\"No data retrieved. Check tickers or date range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f4832-be94-4fa3-abb1-150d51eee276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"sp500_stocks_custom_range67.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the actual top 70 S&P 500 tickers from the market\n",
    "top_70_tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"GOOG\", \"BRK.B\", \"NVDA\", \"TSLA\", \"META\", \"V\", \"UNH\", \"JNJ\", \"XOM\", \"JPM\", \"WMT\", \"MA\", \"PG\", \"LLY\", \"HD\", \"CVX\", \"MRK\", \"ABBV\", \"PEP\", \"KO\", \"AVGO\", \"COST\", \"MCD\", \"DHR\", \"ACN\", \"TXN\", \"LIN\", \"NEE\", \"VZ\", \"WFC\", \"BMY\", \"PM\", \"SCHW\", \"MS\", \"RTX\", \"UPS\", \"UNP\", \"INTC\", \"LOW\", \"QCOM\", \"HON\", \"ORCL\", \"AMT\", \"IBM\", \"TMO\", \"CAT\", \"GS\", \"MDT\", \"BLK\", \"LMT\", \"CB\", \"NOW\", \"SPGI\", \"TGT\", \"ISRG\", \"DE\", \"ADI\", \"GE\",\"PYPL\", \"ADBE\", \"NFLX\", \"CSCO\", \"AMGN\", \"CRM\", \"MO\", \"SO\"]\n",
    "\n",
    "# Filter the dataset for only the top 70 tickers\n",
    "top_70_stocks = df[df['Ticker'].isin(top_70_tickers)]\n",
    "\n",
    "# Save to a new CSV file\n",
    "top_70_file_path = \"top_70_sp500_stocksy5.csv\"\n",
    "top_70_stocks.to_csv(top_70_file_path, index=False)\n",
    "\n",
    "print(f\"Top 70 stocks saved to {top_70_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad64ef-0d24-43c1-8646-80be3b4476ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
